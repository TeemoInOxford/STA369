---
title: "STA 369 Class 02 @ HD & Lecture 03 @ UOA"
author: "Tianyi He"
date: "2024-07-27"
output:
    cleanrmd::html_document_clean:
      theme: null
      mathjax: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lecture 03 - data manipulation

## 1. `separate()` 示例

我们使用 R 自带的 `mtcars` 数据集，将汽车品牌和型号分开：

```{r separate-example, echo=TRUE, message=FALSE, warning=FALSE}
# 加载所需包
library(tidyr)
library(dplyr)
library(tibble)

# 加载mtcars数据集
data(mtcars)

# 假设我们要分离汽车品牌和型号
# 首先，创建一个包含品牌和型号的字符串列
mtcars$model_str <- rownames(mtcars)

# 使用separate()函数分离品牌和型号
mtcars_separated <- separate(mtcars, model_str, into = c("brand", "model"), sep = " ")

# 查看分离后的数据集
head(mtcars_separated[, c("brand", "model")])
```

## 2. `mutate()` 示例

我们在 mtcars 数据集中添加一个新的列，计算每辆车的每加仑油耗的燃油效率（mpg）：

```{r}
# 加载mtcars数据集
data(mtcars)

# 使用mutate()函数添加新列 'mpg_efficiency'
mtcars_with_mpg <- mutate(mtcars, mpg_efficiency = 30 / mpg)

# 查看添加新列后的数据集
head(mtcars_with_mpg[, c("mpg", "mpg_efficiency")])

```

## 3. `summarise()` 示例

计算 mtcars 数据集中每加仑油耗（mpg）的平均值和标准差：

```{r}
# 使用summarise()函数计算每加仑油耗的平均值和标准差
summary_stats <- mtcars %>%
  summarise(
    avg_mpg = mean(mpg, na.rm = TRUE),
    sd_mpg = sd(mpg, na.rm = TRUE)
  )

# 查看汇总结果
summary_stats

```

## 4. 分组操作 (`group_by()` 和 `summarise()`)

按气缸数分组，并计算每组中每加仑油耗的平均值和标准差：

```{r}
# 使用group_by()和summarise()进行分组汇总
grouped_summary <- mtcars %>%
  group_by(cyl) %>%
  summarise(
    avg_mpg = mean(mpg, na.rm = TRUE),
    sd_mpg = sd(mpg, na.rm = TRUE)
  )

# 查看分组汇总结果
grouped_summary

```

## 5. 数据连接操作

### 5.1 `left_join()`

将保留左侧数据集中的所有行：

```{r}
# 加载所需包
library(dplyr)
library(tibble)

# 创建mtcars_info数据集
mtcars_info <- mtcars %>%
  rownames_to_column(var = "model") %>%
  select(model, mpg, cyl, hp)

# 创建mtcars_extra数据集
mtcars_extra <- data.frame(
  model = c("example 1", "example 2", "example 3", "example 4", "Mazda RX4", "Mazda RX4 Wag", "example 11", "example 22", "example 33", "example 44", "example 111", "example 222", "example 333", "example 444", "example 1111", "example 2222", "example 3333", "example 4444", "example 15", "example 25"),
  manufacturer = rep(c("Ford", "Chevrolet"), length.out = 20),
  year = rep(2020:2021, length.out = 20)
)

# 使用left_join()连接数据集
left_join_result <- left_join(mtcars_info, mtcars_extra, by = "model")

# 查看结果
left_join_result

```

### 5.2 `right_join()`

将保留右侧数据集中的所有行：

```{r}
# 使用right_join()连接数据集
right_join_result <- right_join(mtcars_info, mtcars_extra, by = "model")

# 查看结果
right_join_result

```

### 5.3 `full_join()`

将保留两个数据集中的所有行：

```{r}
# 使用full_join()连接数据集
full_join_result <- full_join(mtcars_info, mtcars_extra, by = "model")

# 查看结果
full_join_result

```

### 5.4 `inner_join()`

仅保留两个数据集中的匹配行：

```{r}
# 使用inner_join()连接数据集
inner_join_result <- inner_join(mtcars_info, mtcars_extra, by = "model")

# 查看结果
inner_join_result

```

# Lecture 04 -  Regression

## 1. 数据生成

我们首先生成一组模拟数据，这些数据遵循简单线性关系：

```{r data-generation, echo=TRUE}
# 加载所需包
library(ggplot2)

# 设置随机种子以确保结果可重复
set.seed(123)

# 生成模拟数据
n <- 100
x <- rnorm(n, mean = 50, sd = 10)
beta0 <- 5
beta1 <- 2
epsilon <- rnorm(n, mean = 0, sd = 3)
y <- beta0 + beta1 * x + epsilon

# 创建数据框
data <- data.frame(x = x, y = y)

# 查看前几行数据
head(data)
```

## 2. 拟合线性回归模型

我们使用 lm() 函数来拟合简单线性回归模型：

```{r}

# 拟合线性回归模型
model <- lm(y ~ x, data = data)

# 查看模型摘要
summary(model)

```

得出的结论：

-   Since the p-value of `2e-16 < 0.05`, we have enough evidence to conclude that x is significant.
-   `97.48%` of y can be explained by `x`.
-   For every unit increased in `x`, `y` will be increased by `1.98426` unit.
-   The equation of the model can be written by `y = 5.47867 + 1.98426 * x`.

## 3. 预测和结果可视化

我们可以使用拟合的模型进行预测，并将结果可视化：

```{r message=FALSE, warning=FALSE}
# 预测值
data$predicted_y <- predict(model, newdata = data)

# 绘制数据和拟合线
ggplot(data, aes(x = x, y = y)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(aes(y = predicted_y), method = "lm", color = "red") +
  labs(title = "简单线性回归模型",
       x = "自变量 x",
       y = "因变量 y") +
  theme_minimal()

```

#### RSS

每一个蓝点到红线之间的距离的平方，全部相加，得到的就是`RSS`.

##### 为什么要加这个平方？

-   放大误差：使得模型对大的误差更加敏感
-   避免负值：避免因为正负值互相抵消而被忽略的拟合好坏

记一下三个公式：

$$RSS = \sum_{i} (y_i - \hat{y}_i)^2$$
$$TSS = \sum_{i} (y_i - \bar{y}_i)^2$$
$$R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}$$


-   The observations are independent.

-   The **true** relationship between $X$ and $Y$ is linear.

-   For the error term is normally distributed and of a constant variance, i.e. $Y = X \beta + \epsilon$, $\epsilon \sim \text{Normal}(\mu, \sigma)$.

    -   Errors are independent.

    -   Errors are independent with $X$.

    -   Errors are normally distributed.

    -   Homoscedasticity of errors (equal-variance).

## 4. 模型诊断

检查模型的诊断信息，包括残差和拟合值：

```{r}
# 绘制残差图
par(mfrow = c(2, 2))
plot(model)

```

## Transformation & Interaction

### 1. 数据生成

我们首先生成一组模拟数据，并添加一个交互作用项：

```{r data-generation1, echo=TRUE}
# 加载所需包
library(ggplot2)
library(dplyr)

# 设置随机种子以确保结果可重复
set.seed(123)

# 生成模拟数据
n <- 100
x1 <- rnorm(n, mean = 50, sd = 10)
x2 <- rnorm(n, mean = 30, sd = 5)
beta0 <- 10
beta1 <- 2
beta2 <- 3
beta12 <- 1.5
epsilon <- rnorm(n, mean = 0, sd = 5)
y <- beta0 + beta1 * x1 + beta2 * x2 + beta12 * x1 * x2 + epsilon

# 创建数据框
data <- data.frame(x1 = x1, x2 = x2, y = y)

# 查看前几行数据
head(data)
```

### 2. 数据变换

我们对 `x1` 和 `y` 进行对数变换，观察变换对模型的影响：

```{r}
# 对数变换
data$log_x1 <- log(data$x1 + 1) # +1 避免对数计算中的负值
data$log_y <- log(data$y + 1)   # +1 避免对数计算中的负值

# 拟合变换后的线性回归模型
model_transformed <- lm(log_y ~ log_x1 + x2, data = data)

# 查看模型摘要
summary(model_transformed)

```

### 3. 交互作用

我们将拟合一个包含 `x1` 和 `x2` 交互作用项的线性回归模型：

```{r}
# 拟合包含交互作用项的线性回归模型
model_interaction <- lm(y ~ x1 * x2, data = data)

# 查看模型摘要
summary(model_interaction)

```

### 4. 结果可视化

#### 4.1 数据变换后的结果可视化

```{r message=FALSE, warning=FALSE}
# 绘制原始数据
p1 <- ggplot(data, aes(x = x1, y = y)) +
  geom_point(color = "blue", alpha = 0.6) +
  labs(title = "原始数据",
       x = "自变量 x1",
       y = "因变量 y") +
  theme_minimal()

# 绘制对数变换后的数据
p2 <- ggplot(data, aes(x = log_x1, y = log_y)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red") +
  labs(title = "对数变换后的数据",
       x = "对数变换后的 x1",
       y = "对数变换后的 y") +
  theme_minimal()

# 显示图形
library(gridExtra)
grid.arrange(p1, p2, nrow = 2)

```

#### 4.2 交互作用项的可视化

```{r message=FALSE, warning=FALSE}
# 绘制包含交互作用的模型预测
data$predicted_y <- predict(model_interaction, newdata = data)

# 生成交互作用效果图
ggplot(data, aes(x = x1, y = predicted_y, color = factor(x2))) +
  geom_point(alpha = 0.6) +
  geom_line(aes(group = x2), size = 1) +
  labs(title = "交互作用模型的预测结果",
       x = "自变量 x1",
       y = "预测的 y",
       color = "自变量 x2") +
  theme_minimal() +
  theme(legend.position = "none")

```


#### 数据变换的意义
##### **对数变换（Log Transformation）**：

- **目的**：对数变换通常用于处理数据中的非线性关系或异方差性（即方差不恒定）。它可以使数据分布更加接近正态分布，从而使模型假设更符合实际情况。
- **效果**：对数变换可以使得数据中的极端值影响减小，帮助改善模型的拟合效果和解释能力。

#### 交互作用的意义
##### **交互作用（Interaction）**：

- **目的**：交互作用项用于表示自变量之间的相互影响。简单来说，如果一个自变量对因变量的影响依赖于另一个自变量的水平，那么这两个自变量之间存在交互作用。
- **效果**：引入交互作用项可以帮助捕捉这种复杂关系，从而使模型对数据的拟合更加准确。


## Bootstrap

### 1. 数据生成

我们生成一组模拟数据：

```{r data-generation2, echo=TRUE, message=FALSE, warning=FALSE}
# 加载所需包
library(ggplot2)
library(dplyr)

# 设置随机种子以确保结果可重复
set.seed(123)

# 生成模拟数据
n <- 100
x <- rnorm(n, mean = 50, sd = 10)
beta0 <- 5
beta1 <- 2
epsilon <- rnorm(n, mean = 0, sd = 3)
y <- beta0 + beta1 * x + epsilon

# 创建数据框
data <- data.frame(x = x, y = y)

# 查看前几行数据
head(data)
```

### 2. Bootstrap 方法
我们使用 Bootstrap 方法来估计线性回归模型参数的标准误差：

```{r message=FALSE, warning=FALSE}
# 加载所需包
library(boot)

# 定义回归模型函数
boot_fn <- function(data, indices) {
  d <- data[indices, ]  # 重新抽样
  fit <- lm(y ~ x, data = d)
  return(coef(fit))
}

# 进行Bootstrap抽样
set.seed(123)
bootstrap_results <- boot(data, statistic = boot_fn, R = 1000)

# 查看Bootstrap结果
print(bootstrap_results)

```

### 3. Sandwich 方法
我们使用 Sandwich 方法来计算稳健标准误差：

```{r message=FALSE, warning=FALSE}

# 加载所需包
library(sandwich)
library(lmtest)

# 拟合线性回归模型
model <- lm(y ~ x, data = data)

# 计算稳健标准误差
robust_se <- coeftest(model, vcov = vcovHC(model, type = "HC1"))

# 查看结果
print(robust_se)

```

### 4. 结果解释
我们可以将标准回归结果与稳健标准误差进行对比：

```{r}
# 标准回归结果
summary(model)$coefficients

# Bootstrap结果
bootstrap_results

# Sandwich结果
robust_se

```


# Lecture 05 - The Bias-Variance trade-off


